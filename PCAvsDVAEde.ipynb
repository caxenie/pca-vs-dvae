{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hauptkomponentenanalyse\n",
    "# (Principal Component Analysis, PCA)\n",
    "# vs. \n",
    "# Denoising Variational Autoencoders\n",
    "\n",
    "### _an Hand von Beispielen_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "jupyter nbconvert PCAvsDVAEde.ipynb --to slides --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eine intuitive Perspektive ...\n",
    "\n",
    "#### \"... realistische, hochdimensionale Daten konzentrieren sich in der Nähe einer nichtlinearen, niedrigdimensionalen Mannigfaltigkeit ...\" [Lei et al., 2018]\n",
    "\n",
    "![](manifold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eine intuitive Perspektive ...\n",
    "\n",
    "#### Aber wie lernt man die Mannigfaltigkeit und die Wahrscheinlichkeitsverteilung darauf?\n",
    "![](manifold-generic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. DVAE an Hand von Beispielen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. DVAE an Hand von Beispielen\n",
    "\n",
    "Der __MNIST (Modified National Institute of Standards and Technology) Datensatz__ von handgeschriebenen Zahlen besteht aus __60,000 Trainings- und 10,000 Test-Beispielen__. Die Zahlen wurden hinsichtlich Ihrer Größe __normalisiert und in einem Bild fester Größe zentriert__. \n",
    "![](mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vorstellung der Wettbewerber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA \n",
    "\n",
    "* __Unüberwachtes__ Lernen\n",
    "* __Lineare Transformation__\n",
    "![](pca-intuition.png)\n",
    "* __\"Transformiere\"__ eine Menge von Beobachtungen in ein __anderes Koordinatensystem__, in dem die Werte der ersten Koordinate (Komponente) die __größtmögliche Varianz__ aufweisen [Friedman et al., 2017]\n",
    "* Die __resultierenden Koordinaten (Komponenten)__ sind __nicht__ mit den ursprünglichen Koordinaten __korreliert__    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA \n",
    "\n",
    "![](svd-graphic-simple.png)\n",
    "* Wird zur __Dimensions-Reduzierung__ genutzt (Komprimierung)\n",
    "* Die __Rekonstruktion der Beobachtungen__(\"decoding\") aus den führenden __Hauptkomponenten__ hat den __niedrigsten quadratischen Fehler__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "* unüberwachtes __neuronales Netz__\n",
    "* __minimiert__ den Fehler zwischen Rekonstruktionen und Beobachtungen [Goodfellow et al., 2016]\n",
    "* lernt die __Identitätsfunktion__\n",
    "* wird mit Hilfe von __Fehlerrückführung (Backpropagation) trainiert__\n",
    "* aufgetrennt um __Kodierung und Dekodierung__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "Das folgende Schaubild zeigt eine typische __Autoencoder Pipeline__ \n",
    "\n",
    "![](autoencoder-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. Autoencoders\n",
    "## Funktionalität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. Autoencoders\n",
    "\n",
    "*  Ein __Autoencoder__ mit einer einzelnen __voll verbundenen (fully-connected) versteckten Ebene__, einer __linearen Aktivierungsfunktion__ und dem __quadratischen Fehler als Kostenfunktion__ ist __eng mit der PCA verwandt__ - seine __Gewichten__ spannen den __Untervektorraum der Hauptkomponenten__ auf [Plaut, 2018]\n",
    "\n",
    "\n",
    "* Bei __Autoencodern__ sorgt die __diagonale Approximation beim Kodiervorgang__ zusammen mit der __inhärenten Stochastizität__ für lokale __Orthogonalität beim Dekodieren__  [Rolinek et al, 2019]\n",
    "\n",
    "\n",
    "* Der Unterschied besteht darin, dass bei der __Ausgabe von Autoencodern__, im Gegensatz zur PCA, die __Koordinaten korreliert__ und __nicht der Größe (im Hinblick auf die Varianz) nach absteigend sortiert sind__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. Autoencoders \n",
    "# Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import all necessary libs\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "# we use Keras to implement, layer-by-layer the DVAE and PCA\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose,Reshape\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "%matplotlib inline\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lineare Transformation\n",
    "\n",
    "Es sei $\\{y_i\\}^N_{i=1}$ eine Menge von $N$ Beobachtungs-Vektoren der Dimension $n$ mit $n\\leq N$.\n",
    "\n",
    "Eine __lineare Transformation__ eines __endlich-dimensionalen__ Vektors kann als __Matrix Multiplikation__ ausgedrückt werden: \n",
    "\n",
    "$$ \\begin{align} x_i = W y_i \\end{align} $$  \n",
    "  \n",
    "mit $y_i \\in R^{n}, x_i \\in R^{m}$ und $W \\in R^{nxm}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lineare Transformation\n",
    "\n",
    "* Das $j-te$ Element in $x_i$ ist das __Innere Produkt__ von $y_i$ und der $j-ten$ Spalte der Matrix $W$, welche wir durch $w_j$ bezeichen. Es sei $Y \\in R^{nxN}$ die Matrix, welche wir durch horizontale Aneinanderreihung der Vektoren $\\{y_i\\}^N_{i=1}$ erhalten, \n",
    "\n",
    "$$ Y = \\begin{bmatrix} | ... | \\\\ y_1 ... y_N \\\\ | ... | \\end{bmatrix} $$\n",
    "\n",
    "* Aus der __linearen Transformation__ folgt:\n",
    "\n",
    "$$ X = W^TY,  X_0 = W^TY_0, $$\n",
    "\n",
    "wobei $Y_0$ die __Matrix der zentrierten Elemente__ (d.h. wir subtrahieren den Mittelwert von jeder Beobachtung) bezeichnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximale Varianzkomponenten, Kovarianz und Dekorrelation\n",
    "\n",
    "* Wenn $W^T$ Transformation darstellt, welche die __Hauptkomponentenanalyse__ bezeichnet, so bezeichnen wir $W = P$. Jede Spalte der Matrix $P$, welche durch  $\\{p_j\\}^n_{j=1}$ bezeichnen, ist ein __Ladungs-Vektor__, wohingegen jeder transformierte Vektor $\\{x_i\\}^N_{i=1}$ eine __Hauptkomponente__ ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dimensionsreduzierung, Komprimierung\n",
    "\n",
    "PCA wird zur __Dimensions-Reduktion__ verwendet, da sie durch die durch eine lineare Transformation die __Anzahl der Variablen reduziert__. Dies wird erreicht, indem man die ersten $m$ Hauptkomponenten $(m < n)$ erhält und die folgende Gleichung anwendet:\n",
    "\n",
    "$$ X_m = P_m^TY$$\n",
    "\n",
    "Da nur die ersten $m$ Hauptkomponenten erhalten werden, __verliert__ PCA __information__ (d.h. __verlustreiche Komprimierung__). Der __Verlust__ wird jedoch durch die __Maximierung der Komponenten-Varianzen minimiert__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimaler quadratischer Gesamtrekonstruktionsfehler\n",
    "\n",
    "Die Transformations-Matrix $P_m$ kann ebenfalls durch Lösung der folgenden Gleichung berechnet werden:\n",
    "\n",
    "$$ \\min_{W \\in R^{nxm}} \\| Y_0 - WW^TY_0 \\|_F^2, W^TW = I_{mxm}$$\n",
    "\n",
    "wobei $F$ die Frobenius-Norm bezeichnet. \n",
    "\n",
    "Daraus folgt, dass $P_m$ __jeden zentrierten Vektor__ der Länge $n$ in einen Vektor der Länge $m$ mit ($ m < n$) derart __komprimiert__, dass die __Summe des quadratischen Rekonstruktions-Fehlers minimiert wird__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Skalierung\n",
    "\n",
    "Zur Berechung der $m$ größten Eigenwerte von $Y_0Y_0^T$ können viele verschiedene __iterative Algorithmen__ eingesetzt werden \n",
    "* QR Algorithmen\n",
    "* Jacobi Algorithmus\n",
    "* Power methode\n",
    "* Singulärwert-Zerlegung (Singular Value Decomposition, SVD)\n",
    "\n",
    "Für __sehr große Datenmengen__ eignen sich diese Algorithmen __nicht__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# analytical PCA of the training set\n",
    "def analytical_pca(y):\n",
    "    # variance to explain\n",
    "    pca = PCA(0.7)\n",
    "    # apply PCA\n",
    "    pca.fit(y)\n",
    "    # extract the components \n",
    "    loadings = pca.components_\n",
    "    # apply the transformation\n",
    "    components = pca.transform(y)\n",
    "    # reconstruct from components for visualization\n",
    "    filtered = pca.inverse_transform(components)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment Parametrierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# training params for PCA vs. DVAE\n",
    "num_train = 50000\n",
    "n_images = 6\n",
    "batch_size = 205\n",
    "original_dim = 784\n",
    "latent_dim = 8\n",
    "epochs = 1000\n",
    "epsilon_std = 1.0\n",
    "noise_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get the MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# prepare data for PCA\n",
    "# training\n",
    "x_test_pca = x_test\n",
    "shape_x_test = x_test_pca.shape                                                               \n",
    "pcaInputTest = np.reshape(x_test,[shape_x_test[0],shape_x_test[1]*shape_x_test[2]]).astype('float32')/255\n",
    "# prepare data for DVAE                                      \n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), 28,28,1))\n",
    "x_test = x_test.reshape((len(x_test), 28,28,1))\n",
    "noise_train = x_train + noise_factor * np.random.randn(*x_train.shape)\n",
    "noise_test = x_test + noise_factor * np.random.randn(*x_test.shape)\n",
    "# clip the images to be between 0 and 1\n",
    "noise_train = np.clip(noise_train, 0., 1.)\n",
    "noise_test = np.clip(noise_test, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# display the images (28x28 px)\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * 2, digit_size * n_images))\n",
    "showidx=np.random.randint(0,num_train,n_images)\n",
    "# display input, noisy input\n",
    "for i,idx in enumerate (showidx):\n",
    "    figure[0: 28,i *28: (i + 1) * 28] = np.reshape(x_train[idx], [28, 28])\n",
    "    figure[28: 56,i *28: (i + 1) * 28] = np.reshape(noise_train[idx], [28, 28])\n",
    "plt.figure(figsize=(28*2, 28*n_images))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](sample-input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Für jeden Eingangsvektor $x$ der Dimension $d$ des kompletten Datensaztes der Länge $n$ generiert das neuronale Netz eine Rekonstruktion $x'$ durch:\n",
    "\n",
    "* __Kodierung der Eingangsdaten__ (d.h. verwende die lineare / nicht-lineare Transformation $g_\\phi(.)$)\n",
    "* dies liefert eine __komprimierte Kodierung__ in der dünnsten Netzwerk-Ebene, $z$\n",
    "* __Dekodierung der komprimierten Eingangsdaten__ durch Anwendung der linearen / nicht-linearen Transformation $f_\\theta(.)$\n",
    "\n",
    "![](autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die __Parameter $(\\theta, \\phi)$ werden im Verlauf des Training derart optimiert__, dass ein den Eingangsdaten möglichst ähnliches Ergebnis , $x \\approx f_\\theta(g_\\phi(x))$, produziert wird. In anderen Worten: __die Indentitäts-Funktion wird erlernt__.\n",
    "\n",
    "__Metriken um die Ähnlichkeit zwischen Eingangsdaten und Rekonstruktion__: __Cross-Entropy (bei sigmoid Aktivierungsfuntionen)__, __mittlere quadratische Fehler (MSE)__ etc.:\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n}(x^{i} - f_\\theta(g_\\phi(x^{i}))^2$$\n",
    "\n",
    "![](autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Denoising Variational Autoencoders (DVAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Das Funktionsprinzip __unterscheidet sich__ vom grundlegenden Autoencoder dahingehend, dass ein gewisses Maß an __Störrauschen__  (einer __gewissen Wahrscheinlichkeitsverteilung__ folgend) den __Eingangsdaten hinzugefügt wird__ und dass die __verborgenen Ebenen__ dieses Rauschen __ausgleichen muss__ um die Eingangsdaten zu __rekonstruieren__ [Im, Bengio et al., 2017, Kingma et al., 2017].\n",
    "![](denoising-variational-autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Für jeden gestörten Eingangsvektor $\\tilde x$ eines originalen Vektors $x$ der Dimension $d$, generiert das neuronale Netz eine Rekonstruktion $x'$ durch:\n",
    "* __Kodierung der Eingangsdaten__, welche die Abbildung als Wahrscheinlichkeit der Schätzung von $z$ unter Verwendung der Eingangsdaten darstellt\n",
    "* dies liefert eine __komprimierte Kodierung in der dünnsten Netzwerk-Ebene__ $z$, welche der Verteilung $q_\\phi(z|x)$ folgt\n",
    "* __Dekodierung der komprimierten Eingangsdaten__ an der Ausgangsebene unter Einhaltung des __Beobachtungs-Modells__ $p_\\theta(x|z)$\n",
    "\n",
    "![](denoising-variational-autoencoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "# encoder part\n",
    "x_noise = Input(shape=(28,28,1))\n",
    "conv_1 = Conv2D(64,(3, 3), padding='valid',activation='relu')(x_noise)\n",
    "conv_2 = Conv2D(64,(3, 3), padding='valid',activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D((2, 2))(conv_2)\n",
    "conv_3 = Conv2D(32,(3, 3), padding='valid',activation='relu')(pool_1)\n",
    "pool_2 = MaxPooling2D((2, 2))(conv_3)\n",
    "h=Flatten()(pool_2)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "# reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "# decoder part\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "z=Reshape([1,1,latent_dim])(z)\n",
    "conv_0T = Conv2DTranspose(128,(1, 1), padding='valid',activation='relu')(z)#1*1\n",
    "conv_1T = Conv2DTranspose(64,(3, 3), padding='valid',activation='relu')(conv_0T)#3*3\n",
    "conv_2T = Conv2DTranspose(64,(3, 3), padding='valid',activation='relu')(conv_1T)#5*5\n",
    "conv_3T = Conv2DTranspose(48,(3, 3), strides=(2, 2),padding='same',activation='relu')(conv_2T)#10*10\n",
    "conv_4T = Conv2DTranspose(48,(3, 3), padding='valid',activation='relu')(conv_3T)#12*12\n",
    "conv_5T = Conv2DTranspose(32,(3, 3), strides=(2, 2),padding='same',activation='relu')(conv_4T)#24*24\n",
    "conv_6T = Conv2DTranspose(16,(3, 3), padding='valid',activation='relu')(conv_5T)#26*26\n",
    "x_out = Conv2DTranspose(1,(3, 3), padding='valid',activation='sigmoid')(conv_6T)#28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der DVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DVAE\n",
    "\n",
    "* DVAE __Verlustfunktion__ beinhaltet die Erstellung von Beispielen aus $z \\backsim q_\\phi(z|x)$. Dies ist ein __stochastischer Prozess__ und eignet sich daher __nicht zur Fehlerrückführung__.\n",
    "\n",
    "\n",
    "* Die __geschätzte Posteriori-Verteilung $q_\\phi(z|x)$__ approximiert die tatsächliche Verteilung $p_\\theta(z|x)$. \n",
    "\n",
    "\n",
    "* Wir können die __Kullback-Leibler Abweichung__, $D_{KL}$  benutzen um die __Differenz der beiden Verteilungen__ zu quantifizieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DVAE\n",
    "\n",
    "Durch __Minimierung des Verlusts__, __maximieren__ wir daher die __untere Schranke der Wahrscheinlichkeit__ (__evidence lower bound (ELBO)__) zur Generierung echter Daten-Beispiele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "# instantiate model\n",
    "dvae = Model(x_noise, x_out)\n",
    "dvae.summary()\n",
    "\n",
    "# Compute loss\n",
    "def DVAE_loss(x_origin,x_out):\n",
    "    x_origin=K.flatten(x_origin)\n",
    "    x_out=K.flatten(x_out)\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x_origin, x_out)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    dvae_loss = K.mean(xent_loss + kl_loss)\n",
    "    return dvae_loss\n",
    "\n",
    "# compile the model\n",
    "dvae.compile(optimizer='adam', loss=DVAE_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](network-layout.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Train the DVAE\n",
    "dvae.fit(noise_train,x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(noise_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](training-progress.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison PCA vs. DVAE\n",
    "# testing the DVAE\n",
    "num_test=10000\n",
    "showidx=np.random.randint(0,num_test,n_images)\n",
    "x_out=dvae.predict(x_test[showidx])\n",
    "\n",
    "# prepare data for testing PCA\n",
    "pcaOutput = analytical_pca(pcaInputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Display results\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * 4, digit_size * n_images))\n",
    "for i,idx in enumerate (showidx):\n",
    "    figure[0: 28,i *28: (i + 1) * 28] = np.reshape(x_test[idx], [28, 28]) # input data\n",
    "    figure[28: 28 * 2,i *28: (i + 1) * 28] = np.reshape(noise_test[idx], [28, 28]) # noisy input data \n",
    "    figure[28 * 2: 28 * 3,i *28: (i + 1) * 28] = np.reshape(x_out[i], [28, 28]) # DVAE output\n",
    "    figure[28 * 3: 28 * 4,i *28: (i + 1) * 28] = np.reshape(pcaOutput[idx], [28, 28]) # PCA output\n",
    "plt.figure(figsize=(28 * 4, 28*n_images))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.savefig('inference_output.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML \n",
    "<style>\n",
    "td {\n",
    "  font-size: 15px\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich von PCA und DVAE\n",
    "\n",
    "### Inferenz\n",
    "\n",
    "![](inference_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich von PCA und DVAE\n",
    "\n",
    "### Kostenfunktion\n",
    "\n",
    "![](loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich zwischen PCA und DVAE\n",
    "\n",
    "![](comparison-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich zwischen PCA und DVAE\n",
    "\n",
    "![](comparison-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lieraturverzeichnis\n",
    "\n",
    "[Goodfellow et al., 2016] Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, MIT Press, 2016.\n",
    "\n",
    "[Friedman et al., 2017] Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer, 2017.\n",
    "\n",
    "[Plaut, 2018] Plaut, E., 2018. From principal subspaces to principal components with linear autoencoders. arXiv preprint arXiv:1804.10253.\n",
    "\n",
    "[Im, Bengio et al., 2017] Im, D.I.J., Ahn, S., Memisevic, R. and Bengio, Y., 2017, February. Denoising criterion for variational auto-encoding framework. In Thirty-First AAAI Conference on Artificial Intelligence.\n",
    "\n",
    "[Rolinek et al, 2019] Rolinek, M., Zietlow, D. and Martius, G., 2019. Variational Autoencoders Pursue PCA Directions (by Accident). In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 12406-12415).\n",
    "\n",
    "[Lei et al., 2018] Lei, N., Luo, Z., Yau, S.T. and Gu, D.X., 2018. Geometric understanding of deep learning. arXiv preprint arXiv:1805.10451.\n",
    "\n",
    "[Kingma et al., 2013] Kingma, D.P. and Welling, M., 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximale Varianzkomponenten, Kovarianz und Dekorrelation\n",
    "\n",
    "* Der erste Ladungs-Vektor ist derjenige Einheitsvektor mit dem das innere Produkt der Beobachtungs-Vektoren die __größte Varianz__ aufweisen:\n",
    "\n",
    "$$ \\max w_1^T Y_0Y_0^Tw_1, w_1^Tw_1 = 1$$\n",
    "\n",
    "* Die Lösung der vorherigen leichung ist der erste Eigenvektor der __Kovarianz-Matrix__ $Y_0Y_0^T$, welcher zum größten Eigenwert gehört.\n",
    "\n",
    "* Die Matrix $P$ kann durch __Diagonalisierung der Kovarianz-Matrix__ berechnet werden:\n",
    "\n",
    "$$ Y_0Y_0^T = P \\Lambda P^{-1} = P \\Lambda P^T $$\n",
    "\n",
    "$\\Lambda = Y_0Y_0^T $ ist eine Diagonal-Matrix, deren Diagonal-Elemente $\\{\\lambda_i\\}^N_{i=1}$ der Größe nach absteigend sortiert sind. $ Y = PX $ liefert die inverse Tranformation. Da die Kovarianz-Matrix von $X$ diagonal ist, ist die PCA eine __dekorrelierende Transformation__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Singulärwert-Zerlegung \n",
    "### (Singular Value Decomposition, SVD)\n",
    "\n",
    "Ein Vektor $v$ der Dimension $N$ ist ein __Eigenvektor__ einer quadratischen N × N Matrix $A$, wenn diese die folgende __lineare Gleichung__ erfüllt\n",
    "\n",
    "$$Av =\\lambda v$$\n",
    "\n",
    "wobei $λ$ ein skalarer Wert ist, welcher als der __zum Eigenvektor v gehörende Eigenwert__ bezeichnet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Singulärwert-Zerlegung \n",
    "### (Singular Value Decomposition, SVD)\n",
    "\n",
    "Die Matrix $Y_0 \\in R^{nxN}$ kann __faktorisert__ werden als $Y_0 = U \\Sigma V^T$, wobei $U \\in R^{nxn}$ und $V \\in R^{NxN}$ __orthogonale Matrizen__ sind und $\\Sigma \\in R^{nxN}$ abgesehen von der Diagonalwerten (den sogenannten __Singulär-Werten__) nur aus Nullen besteht.\n",
    "\n",
    "Die Singulärwertzerlegung von $Y_0$ ist äquivalent zur __Eigenwertzerlegung__ von $Y_0T_0^T$. \n",
    "\n",
    "![](svd-graphic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<style>\n",
    "td {\n",
    "  font-size: 15px\n",
    "}\n",
    "</style>\n",
    "\n",
    "# Vergleich von PCA und DVAE\n",
    "\n",
    "### Lernen der Mannigfaltigkeit\n",
    "\n",
    "|__PCA__|__DVAE__|\n",
    "|:-----|:---|\n",
    "| Kodierung/Dekodierung, keine Robustheit gegen Rauschen | nicht-linear, probabilistische Kodierung/Dekodierung mit Robustheit gegen Rauschen und nicht-linearen Aktivierungsfunktionen|\n",
    "| unkorrelierte Koordinaten | korrelierte Ausgansdaten an der dünnsten Netzwerkebene |\n",
    "| Koordinaten sind in absteigener Reihenfolge der Varianz geordnet | Koordinaten sind ungeordnet |\n",
    "| die Spalten der Transformations-Matrix sind orthonormal | die Spalten der Transformations-Matrix sind nicht notwendigerweise orthonormal |\n",
    "| Robustheit gegenüber moderatem Rauschen mit bekannten Verteilungen | Robustheit gegen eine Vielzahl verschiedener Arten und Größenordnungen an injeziertem Rauschen (masking noise, Gaussian noise, salt-and-pepper noise), da das Entrauschen entscheidung für die Generalisierung ist |\n",
    "| einfacher Algorithmus (ohne Regularisierung), geringe Robustheit | die Punkte in niedrig-dimensionalen Mannifaltigkeiten sind robust gegen Rauschen im hoch-dimensionalen Beobachtungs-Raum |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<style>\n",
    "td {\n",
    "  font-size: 15px\n",
    "}\n",
    "</style>\n",
    "# Vergleich zwischen PCA und DVAE\n",
    "\n",
    "### Training \n",
    "\n",
    "|__PCA__|__DVAE__|\n",
    "|:-----|:---|\n",
    "| Abbildung der Eingangsdaten auf einen festen Vektor | Abbildung der Eingangsdaten auf eine Wahrscheinlichkeitsverteilung |\n",
    "| iterative Methoden: QR Zerlegung, Jacobi Algorithmus, Singulärwertzerlegung | Fehlerrückführung (Backpropagation)  |\n",
    "| aufgrund der Kovarianz-Berechnung ineffizient bei großen Datenmengen | effizient bei großen Datenmengen aufgrund der starken Fähigkeit des Erlernens der Mannigfaltigkeit |\n",
    "| basiert auf der Korrelations-/Kovarianz-Matrix, welche - zumindest in der Theorie - sehr empfindlich gegenüber Ausreißern sein kann | kann Beispiele direkt aus dem Eingangsraum generieren und daher die Eigenschfaten des Eingangsrauschens beschreiben (\"reparametrization trick\") |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
