{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hauptkomponentenanalyse vs. \n",
    "# Denoising Variational Autoencoders\n",
    "\n",
    "## _Intuition, Beispiele und  Formalismus_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "jupyter nbconvert PCAvsDVAE.ipynb --to slides --post serve\n",
    "\n",
    "jupyter-nbextension install rise --py --sys-prefix\n",
    "jupyter-nbextension enable rise --py --sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eine intuitive Perspektive ...\n",
    "\n",
    "#### \"... realistische, hochdimensionale Daten konzentrieren sich in der Nähe einer nichtlinearen, niedrigdimensionalen Mannigfaltigkeit ...\" [Lei et al., 2018]\n",
    "\n",
    "![](manifold.png)\n",
    "\n",
    "#### Aber wie lernt man die Mannigfaltigkeit und die Wahrscheinlichkeitsverteilung darauf?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](manifold-generic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich zwischen PCA und DVAE an Hand von Beispielen\n",
    "\n",
    "Der __MNIST Datensatz__ von handgeschriebenen Zahlen besteht aus __60,000 Trainings- und 10,000 Test-Beispielen__. Dieser gehört zu einem größeren Datensatz, der von NIST zur Verfügung gestellt wird. Die Zahlen wurden hinsichtlich Ihrer Größe __normalisiert und in einem Bild fester Größe zentriert__. \n",
    "\n",
    "![](mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hauptkomponentenanalyse \n",
    "# (Principal Component Analysis, PCA)\n",
    "* __Unüberwachtes__ Lernen\n",
    "* __Lineare Transformation__\n",
    "    * __\"Transformiere\"__ eine Menge von Beobachtungen in ein __anderes Koordinatensystem__, in dem die Werte der ersten Koordinate (Komponente) die __größtmögliche Varianz__ aufweisen [Friedman et al., 2017]\n",
    "    * Die __resultierenden Koordinaten (Komponenten)__ sind __nicht__ mit den ursprünglichen Koordinaten __korreliert__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hauptkomponentenanalyse \n",
    "# (Principal Component Analysis, PCA)\n",
    "\n",
    "* praktische Berechnung\n",
    "    * __Eigenwertzerlegung der Kovarianz-Matrix__\n",
    "    * __Singulärwertzerlegung__ der Beobachtungen\n",
    "* Wird zur __Dimensions-Reduzierung__ genutzt\n",
    "* Die __Rekonstruktion der Beobachtungen__(\"decoding\") aus den führenden __Hauptkomponenten__ hat den __niedrigsten quadratischen Fehler__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der PCA\n",
    "\n",
    "### Lineare Transformation\n",
    "\n",
    "* Es sei $\\{y_i\\}^N_{i=1}$ eine Menge von $N$ Beobachtungs-Vektoren der Dimension $n$ mit $n\\leq N$.\n",
    "\n",
    "* Eine __lineare Transformation__ eines __endlich-dimensionalen__ Vektors kann als __Matrix Multiplikation__ ausgedrückt werden: \n",
    "\n",
    "$$ \\begin{align} x_i = W y_i \\end{align} $$  \n",
    "  \n",
    "mit $y_i \\in R^{n}, x_i \\in R^{m}$ und $W \\in R^{nxm}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der PCA\n",
    "\n",
    "### Lineare Transformation\n",
    "\n",
    "* Das $j-te$ Element in $x_i$ ist das __Innere Produkt__ von $y_i$ und der $j-ten$ Spalte der Matrix $W$, welche wir durch $w_j$ bezeichen. Es sei $Y \\in R^{nxN}$ die Matrix, welche wir durch horizontale Aneinanderreihung der Vektoren $\\{y_i\\}^N_{i=1}$ erhalten, \n",
    "\n",
    "$$ Y = \\begin{bmatrix} | ... | \\\\ y_1 ... y_N \\\\ | ... | \\end{bmatrix} $$\n",
    "\n",
    "* Aus der __linearen Transformation__ folgt:\n",
    "\n",
    "$$ X = W^TY,  X_0 = W^TY_0, $$\n",
    "\n",
    "wobei $Y_0$ die __Matrix der zentrierten Elemente__ (d.h. wir subtrahieren den Mittelwert von jeder Beobachtung) bezeichnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximale Varianzkomponenten, Kovarianz und Dekorrelation\n",
    "\n",
    "* Wenn $W^T$ Transformation darstellt, welche die __Hauptkomponentenanalyse__ bezeichnet, so bezeichnen wir $W = P$. Jede Spalte der Matrix $P$, welche durch  $\\{p_j\\}^n_{j=1}$ bezeichnen, ist ein __Ladungs-Vektor__, wohingegen jeder transofmierte Vektor $\\{x_i\\}^N_{i=1}$ eine __Hauptkomponente__ ist.\n",
    "\n",
    "![](pca-intuition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximale Varianzkomponenten, Kovarianz und Dekorrelation\n",
    "\n",
    "* Der erste Ladungs-Vektor ist derjenige Einheitsvektor mit dem das innere Produkt der Beobachtungs-Vektoren die __größte Varianz__ aufweisen:\n",
    "\n",
    "$$ \\max w_1^T Y_0Y_0^Tw_1, w_1^Tw_1 = 1$$\n",
    "\n",
    "* Die Lösung der vorherigen leichung ist der erste Eigenvektor der __Kovarianz-Matrix__ $Y_0Y_0^T$, welcher zum größten Eigenwert gehört.\n",
    "\n",
    "* Die Matrix $P$ kann durch __Diagonalisierung der Kovarianz-Matrix__ berechnet werden:\n",
    "\n",
    "$$ Y_0Y_0^T = P \\Lambda P^{-1} = P \\Lambda P^T $$\n",
    "\n",
    "$\\Lambda = Y_0Y_0^T $ ist eine Diagonal-Matrix, deren Diagonal-Elemente $\\{\\lambda_i\\}^N_{i=1}$ der Größe nach absteigend sortiert sind. $ Y = PX $ liefert die inverse Tranformation. Da die Kovarianz-Matrix von $X$ diagonal ist, ist die PCA eine __dekorrelierende Transformation__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dimensionsreduzierung, Komprimierung, Skalierung\n",
    "\n",
    "PCA wird zur __Dimensions-Reduktion__ verwendet, da sie durch die durch eine lineare Transformation die __Anzahl der Variablen reduziert__. Dies wird erreicht, indem man die ersten $m$ Hauptkomponenten $(m < n)$ erhält und die folgende Gleichung anwendet:\n",
    "\n",
    "$$ X_m = P_m^TY$$\n",
    "\n",
    "Da nur die ersten $m$ Hauptkomponenten erhalten werden, __verliert__ PCA __information__ (d.h. __verlustreiche Komprimierung__). Der __Verlust__ wird jedoch durch die __Maximierung der Komponenten-Varianzen minimiert__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dimensionsreduzierung, Komprimierung, Skalierung\n",
    "\n",
    "Zur Berechung der $m$ größten Eigenwerte von $Y_0Y_0^T$ können viele verschiedene __iterative Algorithmen__ eingesetzt werden \n",
    "* QR Algorithmen\n",
    "* Jacobi Algorithmus\n",
    "* power method\n",
    "* SVD\n",
    "\n",
    "Für __sehr große Datenmengen__ eignen sich diese Algorithmen __nicht__!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimaler quadratischer Gesamtrekonstruktionsfehler\n",
    "\n",
    "Die Transformations-Matrix $P_m$ kann ebenfalls durch Lösung der folgenden Gleichung berechnet werden:\n",
    "\n",
    "$$ \\min_{W \\in R^{nxm}} \\| Y_0 - WW^TY_0 \\|_F^2, W^TW = I_{mxm}$$\n",
    "\n",
    "wobei $F$ die Frobenius-Norm bezeichnet. \n",
    "\n",
    "Daraus folgt, dass $P_m$ __jeden zentrierten Vektor__ der Länge $n$ in einen Vektor der Länge $m$ mit ($ m < n$) derart __komprimiert__, dass die __Summe des quadratischen Rekonstruktions-Fehlers minimiert wird__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Singulärwert-Zerlegung \n",
    "### (Singular Value Decomposition, SVD)\n",
    "\n",
    "Ein Vektor $v$ der Dimension $N$ ist ein __Eigenvektor__ einer quadratischen N × N Matrix $A$, wenn diese die folgende __lineare Gleichung__ erfüllt\n",
    "\n",
    "$$Av =\\lambda v$$\n",
    "\n",
    "wobei $λ$ ein skalarer Wert ist, welcher als der __zum Eigenvektor v gehörende Eigenwert__ bezeichnet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Singulärwert-Zerlegung \n",
    "### (Singular Value Decomposition, SVD)\n",
    "\n",
    "Die Matrix $Y_0 \\in R^{nxN}$ kann __faktorisert__ werden als $Y_0 = U \\Sigma V^T$, wobei $U \\in R^{nxn}$ und $V \\in R^{NxN}$ __orthogonale Matrizen__ sind und $\\Sigma \\in R^{nxN}$ abgesehen von der Diagonalwerten (den sogenannten __Singulär-Werten__) nur aus Nullen besteht.\n",
    "\n",
    "Die Singulärwertzerlegung von $Y_0$ ist äquivalent zur __Eigenwertzerlegung__ von $Y_0T_0^T$. \n",
    "\n",
    "![](svd-graphic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "* unüberwachtes __neuronales Netz__\n",
    "* __minimiert__ den Fehler zwischen Rekonstruktionen und Beobachtungen [Goodfellow et al., 2016]\n",
    "* lernt die __Identitätsfunktion__\n",
    "* wird mit Hilfe von __Fehlerrückführung (Backpropagation) trainiert__ und dann aufgetrennt um __Kodierung und Dekodierung__ zu erreichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "Das folgende Schaubild zeigt eine typische __Autoencoder Pipeline__ \n",
    "\n",
    "![](autoencoder-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der Autoencoder\n",
    "\n",
    "Für jeden Eingangsvektor $x$ der Dimension $d$ des kompletten Datensaztes der Länge $n$ generiert das neuronale Netz eine Rekonstruktion $x'$ durch:\n",
    "\n",
    "* __Kodierung der Eingangsdaten__ (d.h. verwende die lineare / nicht-lineare Transformation $g_\\phi(.)$)\n",
    "* dies liefert eine __verborgende, komprimierte Kodierung__ in der dünnsten Netzwerk-Ebene, $z$\n",
    "* __Dekodierung der komprimierten Eingangsdaten__ durch Anwendung der linearen / nicht-linearen Transformation $f_\\theta(.)$\n",
    "\n",
    "![](autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der Autoencoder\n",
    "\n",
    "Die __Parameter $(\\theta, \\phi)$ werden im Verlauf des Training derart optimiert__, dass ein den Eingangsdaten möglichst ähnliches Ergebnis , $x \\approx f_\\theta(g_\\phi(x))$, produziert wird. In anderen Worten: __die Indentitäts-Funktion wird erlernt__.\n",
    "\n",
    "Es gibt viele verschiedene __Metriken um die Ähnlichkeit zwischen Eingangsdaten und Rekonstruktion__ zu quantifizieren. Beispiele sind __Cross-Entropy (bei sigmoid Aktivierungsfuntionen)__ oder der __mittlere quadratische Fehler (MSE)__:\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n}(x^{i} - f_\\theta(g_\\phi(x^{i}))^2$$\n",
    "\n",
    "![](autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. Autoencoders\n",
    "\n",
    "*  Ein __Autoencoder__ mit einer einzelnen __voll verbundenen (fully-connected) versteckten Ebene__, einer __linearen Aktivierungsfunktion__ und dem __quadratischen Fehler als Kostenfunktion__ ist __eng mit der PCA verwandt__ - seine __Gewichten__ spannen den __Untervektorraum der Hauptkomponenten__ auf [Plaut, 2018]\n",
    "* Bei __Autoencodern__ sorgt die __diagonale Approximation beim Kodiervorgang__ zusammen mit der __inhärenten Stochastizität__ für lokale __Orthogonalität beim Dekodieren__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PCA vs. Autoencoders\n",
    "\n",
    "* Das Verhalten bei Autoencodersn hinsichtlich __Rekonstruktion und Orthogonalität__ ähnelt stark der __Einbettung__, welche bei der __PCA__ gewählt wird [Rolinek et al, 2019]\n",
    "* Der Unterschied besteht darin, dass bei der __Ausgabe von Autoencodern__, im Gegensatz zur PCA, die __Koordinaten korreliert__ und __nicht der Größe (im Hinblick auf die Varianz) nach absteigend sortiert sind__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Denoising Variational Autoencoders (DVAE)\n",
    "\n",
    "Das Funktionsprinzip __unterscheidet sich__ vom grundlegenden Autoencoder dahingehend, dass ein gewisses Maß an __Störrauschen__  (einer __gewissen Wahrscheinlichkeitsverteilung__ folgend) den __Eingangsdaten hinzugefügt wird__ und dass die __verborgenen Ebenen__ dieses Rauschen ausgleichen muss um die Eingangsdaten zu __rekonstruieren__ [Im, Bengio et al., 2017, Kingma et al., 2017].\n",
    "\n",
    "![](denoising-variational-autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Denoising Variational Autoencoders (DVAE)\n",
    "\n",
    "Für jeden gestörten Eingangsvektor $\\tilde x$ eines originalen Vektors $x$ der Dimension $d$, generiert das neuronale Netz eine Rekonstruktion $x'$ durch:\n",
    "* __Kodierung der Eingangsdaten__, welche die Abbildung als Wahrscheinlichkeit der Schätzung von $z$ unter Verwendung der Eingangsdaten darstellt, wobei die __Parameter des Rauschens__ ($\\mu$ and $\\sigma$) bekannt sind, um die Berechnung der Posteriori-Verteilung zu erleichtern\n",
    "* dies liefert eine __verborgende, komprimierte Kodierung in der dünnsten Netzwerk-Ebene__ $z$, welche der Verteilung $q_\\phi(z|x)$ folgt\n",
    "* __Dekodierung der komprimierten Eingangsdaten__ an der Ausgangsebene unter Einhaltung des __Beobachtungs-Modells__ $p_\\theta(x|z)$\n",
    "\n",
    "![](denoising-variational-autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der DVAE\n",
    "\n",
    "Die __Verlustfunktion zur Wiederherstellung__ der ursprünglichen Eingangsdaten (__nicht die gestörten__), $\\tilde{x}^{i} = M(\\tilde{x}^{i} | x^{i}) $.\n",
    "\n",
    "DVAE __Verlustfunktion__ beinhaltet die Erstellung von Beispielen aus $z \\backsim q_\\phi(z|x)$. Dies ist ein __stochastischer Prozess__ und eignet sich daher __nicht zur Fehlerrückführung__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der DVAE\n",
    "\n",
    "Die __geschätzte Posteriori-Verteilung $q_\\phi(z|x)$__ approximiert die tatsächliche Verteilung $p_\\theta(z|x)$. Wir können die __Kullback-Leibler Abweichung__ benutzen um die __Differenz der beiden Verteilungen__ zu quantifizieren. Die KL Abweichung __DKL(X∥Y) misst den Informationsverlust__ wenn die Verteilung Y verwendet wird um X darzustellen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grundlegende Mathematik der DVAE\n",
    "\n",
    "Bei __abweichenden Bayesischen Methoden__ wird die Verlustfunktion auch die abweichende untere Schranke oder auch __evidence lower bound (ELBO)__ genannt. Der “untere Schranke” Teil des Namens rührt daher, dass KL ist nicht-negativ und daher ist der Verlust die untere Schranke von $log p_\\theta(x)$.\n",
    "\n",
    "$$ log p_\\theta(x) - D_{KL}(q_\\phi(z|x) || p_\\theta(z|x)) \\leq log p_\\theta(x) $$\n",
    "\n",
    "Durch __Minimierung des Verlusts__, __maximieren__ wir daher die __untere Schranke der Wahrscheinlichkeit__ zur Generierung echter Daten-Beispiele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import all necessary libs\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose,Reshape\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "%matplotlib inline\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# analytical PCA of the training set\n",
    "def analytical_pca(y):\n",
    "    # variance to explain\n",
    "    pca = PCA(0.7)\n",
    "    # apply PCA\n",
    "    pca.fit(y)\n",
    "    # extract the components \n",
    "    loadings = pca.components_\n",
    "    # apply the transformation\n",
    "    components = pca.transform(y)\n",
    "    # reconstruct from components for visualization\n",
    "    filtered = pca.inverse_transform(components)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# training params for PCA vs. DVAE\n",
    "num_train = 50000\n",
    "n_images = 6\n",
    "batch_size = 256\n",
    "original_dim = 784\n",
    "latent_dim = 8\n",
    "epochs = 10\n",
    "epsilon_std = 1.0\n",
    "noise_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# get the MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# prepare data for PCA\n",
    "shape_x_train = x_train.shape                                                               \n",
    "pcaInput = np.reshape(x_train,[shape_x_train[0],shape_x_train[1]*shape_x_train[2]]).astype('float32')/255      \n",
    "# prepare data for DVAE                                      \n",
    "train_num=50000\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), 28,28,1))\n",
    "x_test = x_test.reshape((len(x_test), 28,28,1))\n",
    "noise_train = x_train + noise_factor * np.random.randn(*x_train.shape)\n",
    "noise_test = x_test + noise_factor * np.random.randn(*x_test.shape)\n",
    "# clip the images to be between 0 and 1\n",
    "noise_train = np.clip(noise_train, 0., 1.)\n",
    "noise_test = np.clip(noise_test, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# display\n",
    "showidx=np.random.randint(0,num_train,n_images)\n",
    "# precalculate PCA\n",
    "pcaOutput = analytical_pca(pcaInput)\n",
    "# display input, noisy input and PCA on noisy input\n",
    "for i,idx in enumerate (showidx):\n",
    "    figure[0: 28,i *28: (i + 1) * 28] = np.reshape(x_train[idx], [28, 28])\n",
    "    figure[28: 56,i *28: (i + 1) * 28] = np.reshape(noise_train[idx], [28, 28])\n",
    "    figure[28 * 2: 28 * 3,i *28: (i + 1) * 28] = np.reshape(pcaOutput[idx], [28, 28])\n",
    "plt.figure(figsize=(28*3, 28*n_images))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "#encoder part\n",
    "x_noise = Input(shape=(28,28,1))\n",
    "conv_1 = Conv2D(64,(3, 3), padding='valid',activation='relu')(x_noise)\n",
    "conv_2 = Conv2D(64,(3, 3), padding='valid',activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D((2, 2))(conv_2)\n",
    "conv_3 = Conv2D(32,(3, 3), padding='valid',activation='relu')(pool_1)\n",
    "pool_2 = MaxPooling2D((2, 2))(conv_3)\n",
    "h=Flatten()(pool_2)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "#reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "#decoder part\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "z=Reshape([1,1,latent_dim])(z)\n",
    "conv_0T = Conv2DTranspose(128,(1, 1), padding='valid',activation='relu')(z)#1*1\n",
    "conv_1T = Conv2DTranspose(64,(3, 3), padding='valid',activation='relu')(conv_0T)#3*3\n",
    "conv_2T = Conv2DTranspose(64,(3, 3), padding='valid',activation='relu')(conv_1T)#5*5\n",
    "conv_3T = Conv2DTranspose(48,(3, 3), strides=(2, 2),padding='same',activation='relu')(conv_2T)#10*10\n",
    "conv_4T = Conv2DTranspose(48,(3, 3), padding='valid',activation='relu')(conv_3T)#12*12\n",
    "conv_5T = Conv2DTranspose(32,(3, 3), strides=(2, 2),padding='same',activation='relu')(conv_4T)#24*24\n",
    "conv_6T = Conv2DTranspose(16,(3, 3), padding='valid',activation='relu')(conv_5T)#26*26\n",
    "x_out = Conv2DTranspose(1,(3, 3), padding='valid',activation='sigmoid')(conv_6T)#28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Implement the DVAE\n",
    "# instantiate VAE model\n",
    "vae = Model(x_noise, x_out)\n",
    "vae.summary()\n",
    "\n",
    "# Implement the DVAE\n",
    "# Compute VAE loss\n",
    "def VAE_loss(x_origin,x_out):\n",
    "    x_origin=K.flatten(x_origin)\n",
    "    x_out=K.flatten(x_out)\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x_origin, x_out)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    return vae_loss\n",
    "vae.compile(optimizer='adam', loss=VAE_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train the DVAE\n",
    "vae.fit(noise_train,x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(noise_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison PCA vs. DVAE\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * 4, digit_size * n_images))\n",
    "num_test=10000\n",
    "showidx=np.random.randint(0,num_test,n_images)\n",
    "x_out=vae.predict(x_test[showidx])\n",
    "# Display\n",
    "for i,idx in enumerate (showidx):\n",
    "    figure[0: 28,i *28: (i + 1) * 28] = np.reshape(x_test[idx], [28, 28])\n",
    "    figure[28: 28 * 2,i *28: (i + 1) * 28] = np.reshape(noise_test[idx], [28, 28])\n",
    "    figure[28 * 2: 28 * 3,i *28: (i + 1) * 28] = np.reshape(x_out[i], [28, 28])\n",
    "    figure[28 * 3: 28 * 4,i *28: (i + 1) * 28] = np.reshape(pcaOutput[idx], [28, 28])\n",
    "\n",
    "plt.figure(figsize=(28 * 4, 28*n_images))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.savefig('result_keras_VAE.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich von PCA und DVAE\n",
    "\n",
    "### Lernen der Mannigfaltigkeit\n",
    "\n",
    "|__PCA__|__DVAE__|\n",
    "|:-----|:---|\n",
    "| Kodierung/Dekodierung, keine Robustheit gegen Rauschen | nicht-linear, probabilistische Kodierung/Dekodierung mit Robustheit gegen Rauschen und nicht-linearen Aktivierungsfunktionen|\n",
    "| unkorrelierte Koordinaten | korrelierte Ausgansdaten an der dünnsten Netzwerkebene |\n",
    "| Koordinaten sind in absteigener Reihenfolge der Varianz geordnet | Koordinaten sind ungeordnet |\n",
    "| die Spalten der Transformations-Matrix sind orthonormal | die Spalten der Transformations-Matrix sind nicht notwendigerweise orthonormal |\n",
    "| Robustheit gegenüber moderatem Rauschen mit bekannten Verteilungen | Robustheit gegen eine Vielzahl verschiedener Arten und Größenordnungen an injeziertem Rauschen (masking noise, Gaussian noise, salt-and-pepper noise), da das Entrauschen entscheidung für die Generalisierung ist |\n",
    "| einfacher Algorithmus (ohne Regularisierung), geringe Robustheit | die Punkte in niedrig-dimensionalen Mannifaltigkeiten sind robust gegen Rauschen im hoch-dimensionalen Beobachtungs-Raum |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vergleich zwischen PCA und DVAE\n",
    "\n",
    "### Training \n",
    "\n",
    "| __PCA__ | __DVAE__ |\n",
    "|-----|------|\n",
    "| Abbildung der Eingangsdaten auf einen festen Vektor | Abbildung der Eingangsdaten auf eine Wahrscheinlichkeitsverteilung |\n",
    "| iterative Methoden: QR Zerlegung, Jacobi Algorithmus, Singulärwertzerlegung | Fehlerrückführung (Backpropagation)  |\n",
    "| aufgrund der Kovarianz-Berechnung ineffizient bei großen Datenmengen | effizient bei großen Datenmengen aufgrund der starken Fähigkeit des Erlernens der Mannigfaltigkeit |\n",
    "| basiert auf der Korrelations-/Kovarianz-Matrix, welche - zumindest in der Theorie - sehr empfindlich gegenüber Ausreißern sein kann | kann Beispiele direkt aus dem Eingangsraum generieren und daher die Eigenschfaten des Eingangsrauschens beschreiben (\"reparametrization trick\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lieraturverzeichnis\n",
    "\n",
    "[Goodfellow et al., 2016] Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, MIT Press, 2016.\n",
    "\n",
    "[Friedman et al., 2017] Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer, 2017.\n",
    "\n",
    "[Plaut, 2018] Plaut, E., 2018. From principal subspaces to principal components with linear autoencoders. arXiv preprint arXiv:1804.10253.\n",
    "\n",
    "[Im, Bengio et al., 2017] Im, D.I.J., Ahn, S., Memisevic, R. and Bengio, Y., 2017, February. Denoising criterion for variational auto-encoding framework. In Thirty-First AAAI Conference on Artificial Intelligence.\n",
    "\n",
    "[Rolinek et al, 2019] Rolinek, M., Zietlow, D. and Martius, G., 2019. Variational Autoencoders Pursue PCA Directions (by Accident). In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 12406-12415).\n",
    "\n",
    "[Lei et al., 2018] Lei, N., Luo, Z., Yau, S.T. and Gu, D.X., 2018. Geometric understanding of deep learning. arXiv preprint arXiv:1805.10451.\n",
    "\n",
    "[Kingma et al., 2013] Kingma, D.P. and Welling, M., 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
